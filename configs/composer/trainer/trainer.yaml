#file: noinspection LongLine
# Composer Trainer
# Need to pass the following at runtime:
#  - model
#  - optimizer (composer.optim),
#  - loggers (list[composer.loggers]),
#  - algorithms (list[composer.algorithms]),
#  - scheduler (composer.optim.scheduler),
#  - callbacks (list[composer.callbacks]),
_target_: composer.Trainer
run_name: ${run_name}
seed: ${seed}
device: ${backend}
train_subset_num_batches: -1
eval_subset_num_batches: -1
max_duration: '1000000ba'
eval_interval: '10000ba'
progress_bar: false
log_to_console: true
console_log_interval: '10ba'
precision: 'amp_bf16'
device_train_microbatch_size: ${div_up:${train_dataloader.batch_size}, ${training.grad_accum}}
save_folder: null  # Checkpointing is handled by hf_compatible_checkpointing callback
load_path: ${training.load_path}
load_weights_only: false
autoresume: ${training.autoresume}
python_log_level: null
dist_timeout: 600.0
